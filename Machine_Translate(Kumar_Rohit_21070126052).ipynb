{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:27.987497Z",
          "iopub.status.busy": "2023-09-23T14:19:27.987134Z",
          "iopub.status.idle": "2023-09-23T14:19:28.346894Z",
          "shell.execute_reply": "2023-09-23T14:19:28.345984Z",
          "shell.execute_reply.started": "2023-09-23T14:19:27.987459Z"
        },
        "id": "M9NVOabakAcz",
        "outputId": "45dbf4ea-4457-484f-a9f4-fc92f5c0882e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/machine-translate/Hindi_English_Truncated_Corpus.csv\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "W6vrl3HfkAc1"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "K39PKLpmkAc3"
      },
      "source": [
        "## Name :Kumar Rohit <br>\n",
        "## PRN : 21070126052 <br>\n",
        "## Batch : AIML - A3 <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "uXKO_9aPkAc3"
      },
      "source": [
        "# 1.2. Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-25T09:36:21.902519Z",
          "start_time": "2023-09-25T09:36:14.384275Z"
        },
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:30.202533Z",
          "iopub.status.busy": "2023-09-23T14:19:30.201706Z",
          "iopub.status.idle": "2023-09-23T14:19:37.101406Z",
          "shell.execute_reply": "2023-09-23T14:19:37.100445Z",
          "shell.execute_reply.started": "2023-09-23T14:19:30.202494Z"
        },
        "id": "wnkD3WRjkAc3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding , LSTM , Dense, RepeatVector , TimeDistributed , Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "import re\n",
        "import string\n",
        "from string import digits\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "spYr9UonkAc3"
      },
      "source": [
        "# 1.3. Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:38.658819Z",
          "iopub.status.busy": "2023-09-23T14:19:38.657777Z",
          "iopub.status.idle": "2023-09-23T14:19:39.837584Z",
          "shell.execute_reply": "2023-09-23T14:19:39.836654Z",
          "shell.execute_reply.started": "2023-09-23T14:19:38.658778Z"
        },
        "id": "jcj1fRo5kAc4",
        "outputId": "fb3e0442-bfb9-4d12-97c7-4c7e08947ec7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "source\n",
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/kaggle/input/machine-translate/Hindi_English_Truncated_Corpus.csv')\n",
        "df['source'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:39.839828Z",
          "iopub.status.busy": "2023-09-23T14:19:39.839473Z",
          "iopub.status.idle": "2023-09-23T14:19:39.979213Z",
          "shell.execute_reply": "2023-09-23T14:19:39.978235Z",
          "shell.execute_reply.started": "2023-09-23T14:19:39.839796Z"
        },
        "id": "UXR02thrkAc4"
      },
      "outputs": [],
      "source": [
        "df = df[(df.english_sentence.apply(lambda x: len(str(x))<=30)) &\n",
        "            (df.hindi_sentence.apply(lambda x: len(str(x))<=30))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6sjFZTJpkAc4"
      },
      "source": [
        "# 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "otB1P8pPkAc4"
      },
      "source": [
        "# 2.1. Changing the Uppercase to Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:40.495132Z",
          "iopub.status.busy": "2023-09-23T14:19:40.494759Z",
          "iopub.status.idle": "2023-09-23T14:19:40.575356Z",
          "shell.execute_reply": "2023-09-23T14:19:40.574381Z",
          "shell.execute_reply.started": "2023-09-23T14:19:40.495103Z"
        },
        "id": "_IHH0ff4kAc4"
      },
      "outputs": [],
      "source": [
        "# Changing uppercase to lowercase\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x:str(x).lower())\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove quotes\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x:re.sub(\"'\",'',x))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"'\",'',x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9lHvoHK3kAc4"
      },
      "source": [
        "# 2.2. Removing the Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:41.234452Z",
          "iopub.status.busy": "2023-09-23T14:19:41.233855Z",
          "iopub.status.idle": "2023-09-23T14:19:41.368932Z",
          "shell.execute_reply": "2023-09-23T14:19:41.368006Z",
          "shell.execute_reply.started": "2023-09-23T14:19:41.234418Z"
        },
        "id": "xqR-1HIbkAc4",
        "outputId": "8d392192-0571-425f-bf64-c9b431d0532c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Punctuations to be excluded :  {'<', '/', '.', '(', '$', ';', '~', '_', ':', '?', '\\\\', ',', '+', '^', '\"', '>', '{', '*', ')', '}', '@', '[', '!', '&', '-', ']', '|', '%', '`', '#', \"'\", '='}\n"
          ]
        }
      ],
      "source": [
        "to_exclude = set(string.punctuation) # Set of all special characters\n",
        "print(\"Punctuations to be excluded : \",to_exclude)\n",
        "\n",
        "# Remove all the special characters\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7szztezEkAc5"
      },
      "source": [
        "# 2.3. Removing the Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:41.657383Z",
          "iopub.status.busy": "2023-09-23T14:19:41.657025Z",
          "iopub.status.idle": "2023-09-23T14:19:41.742274Z",
          "shell.execute_reply": "2023-09-23T14:19:41.741032Z",
          "shell.execute_reply.started": "2023-09-23T14:19:41.657355Z"
        },
        "id": "8pUaFzUGkAc5",
        "outputId": "5e5b2e68-32a7-4d75-93a8-3a6e8783fe31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>category religious text</td>\n",
              "      <td>श्रेणीधर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>this changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>maine</td>\n",
              "      <td>मेन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>can you imagine saying that</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127580</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>google author</td>\n",
              "      <td>गूगल अर्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127581</th>\n",
              "      <td>tides</td>\n",
              "      <td>the die was cast</td>\n",
              "      <td>सांचा ढल गया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127582</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>devotional period</td>\n",
              "      <td>भक्ति काल १३७५१७००</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127590</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>travelling</td>\n",
              "      <td>यात्राएं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127598</th>\n",
              "      <td>ted</td>\n",
              "      <td>thank you</td>\n",
              "      <td>धन्यवाद</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18416 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           source             english_sentence                hindi_sentence\n",
              "11      indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
              "23            ted          this changed slowly          धीरे धीरे ये सब बदला\n",
              "26            ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
              "33      indic2012                        maine                           मेन\n",
              "35            ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है\n",
              "...           ...                          ...                           ...\n",
              "127580  indic2012                google author                     गूगल अर्थ\n",
              "127581      tides            the die was cast                  सांचा ढल गया \n",
              "127582  indic2012            devotional period            भक्ति काल १३७५१७००\n",
              "127590  indic2012                   travelling                      यात्राएं\n",
              "127598        ted                    thank you                      धन्यवाद \n",
              "\n",
              "[18416 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove all the digits\n",
        "from string import digits\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:42.207522Z",
          "iopub.status.busy": "2023-09-23T14:19:42.206850Z",
          "iopub.status.idle": "2023-09-23T14:19:42.316182Z",
          "shell.execute_reply": "2023-09-23T14:19:42.315106Z",
          "shell.execute_reply.started": "2023-09-23T14:19:42.207491Z"
        },
        "id": "XK9K0p9FkAc5",
        "outputId": "4db9fb74-e355-448d-b275-bcbd5cf77715"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>category religious text</td>\n",
              "      <td>श्रेणीधर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>this changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>maine</td>\n",
              "      <td>मेन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>can you imagine saying that</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127580</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>google author</td>\n",
              "      <td>गूगल अर्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127581</th>\n",
              "      <td>tides</td>\n",
              "      <td>the die was cast</td>\n",
              "      <td>सांचा ढल गया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127582</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>devotional period</td>\n",
              "      <td>भक्ति काल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127590</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>travelling</td>\n",
              "      <td>यात्राएं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127598</th>\n",
              "      <td>ted</td>\n",
              "      <td>thank you</td>\n",
              "      <td>धन्यवाद</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18416 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           source             english_sentence                hindi_sentence\n",
              "11      indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
              "23            ted          this changed slowly          धीरे धीरे ये सब बदला\n",
              "26            ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
              "33      indic2012                        maine                           मेन\n",
              "35            ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है\n",
              "...           ...                          ...                           ...\n",
              "127580  indic2012                google author                     गूगल अर्थ\n",
              "127581      tides            the die was cast                  सांचा ढल गया \n",
              "127582  indic2012            devotional period                    भक्ति काल \n",
              "127590  indic2012                   travelling                      यात्राएं\n",
              "127598        ted                    thank you                      धन्यवाद \n",
              "\n",
              "[18416 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove all the digits\n",
        "from string import digits\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LRdTh6tkkAc5"
      },
      "source": [
        "# 2.4. Removing the Extra Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:43.179043Z",
          "iopub.status.busy": "2023-09-23T14:19:43.178665Z",
          "iopub.status.idle": "2023-09-23T14:19:43.304033Z",
          "shell.execute_reply": "2023-09-23T14:19:43.302987Z",
          "shell.execute_reply.started": "2023-09-23T14:19:43.179011Z"
        },
        "id": "8ArVOOV8kAc5",
        "outputId": "5e69d4db-4da2-44f9-d604-d032d18526ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>category religious text</td>\n",
              "      <td>श्रेणीधर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>this changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>maine</td>\n",
              "      <td>मेन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>can you imagine saying that</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127580</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>google author</td>\n",
              "      <td>गूगल अर्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127581</th>\n",
              "      <td>tides</td>\n",
              "      <td>the die was cast</td>\n",
              "      <td>सांचा ढल गया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127582</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>devotional period</td>\n",
              "      <td>भक्ति काल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127590</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>travelling</td>\n",
              "      <td>यात्राएं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127598</th>\n",
              "      <td>ted</td>\n",
              "      <td>thank you</td>\n",
              "      <td>धन्यवाद</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18416 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           source             english_sentence                hindi_sentence\n",
              "11      indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
              "23            ted          this changed slowly          धीरे धीरे ये सब बदला\n",
              "26            ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
              "33      indic2012                        maine                           मेन\n",
              "35            ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है\n",
              "...           ...                          ...                           ...\n",
              "127580  indic2012                google author                     गूगल अर्थ\n",
              "127581      tides             the die was cast                  सांचा ढल गया\n",
              "127582  indic2012            devotional period                     भक्ति काल\n",
              "127590  indic2012                   travelling                      यात्राएं\n",
              "127598        ted                    thank you                       धन्यवाद\n",
              "\n",
              "[18416 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove extra spaces\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.strip())\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.strip())\n",
        "df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "x6ZRbEwRkAc5"
      },
      "source": [
        "# 2.5. Adding the Start and End Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:44.059413Z",
          "iopub.status.busy": "2023-09-23T14:19:44.059055Z",
          "iopub.status.idle": "2023-09-23T14:19:44.144690Z",
          "shell.execute_reply": "2023-09-23T14:19:44.143731Z",
          "shell.execute_reply.started": "2023-09-23T14:19:44.059383Z"
        },
        "id": "6oxGSg9vkAc6"
      },
      "outputs": [],
      "source": [
        "# Create 2 list to send the data\n",
        "input_text = []\n",
        "target_text = []\n",
        "\n",
        "# Creating the characters\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for eng, hin in df[['english_sentence','hindi_sentence']].itertuples(index=False):\n",
        "    target = 'START_ ' + hin + ' _END' # End Sequence\n",
        "    input_text.append(eng)\n",
        "    target_text.append(target)\n",
        "\n",
        "    for char in eng.split():\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "    for hin_char in hin.split():\n",
        "        if hin_char not in target_characters:\n",
        "            target_characters.add(hin_char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "CqXU8O1wkAc6"
      },
      "source": [
        "# 2.6. Printing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:45.614577Z",
          "iopub.status.busy": "2023-09-23T14:19:45.613884Z",
          "iopub.status.idle": "2023-09-23T14:19:45.636957Z",
          "shell.execute_reply": "2023-09-23T14:19:45.635920Z",
          "shell.execute_reply.started": "2023-09-23T14:19:45.614545Z"
        },
        "id": "JC-nNatwkAc6",
        "outputId": "b8fdd69a-7d0a-48f9-b617-3e1620123fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9232\n",
            "8666\n",
            "30\n",
            "42\n"
          ]
        }
      ],
      "source": [
        "# Making the input_char\n",
        "input_char = sorted(list(input_characters))\n",
        "target_char = sorted(list(target_characters))\n",
        "\n",
        "# Encoder definining\n",
        "num_encoder_tokens = len(input_char)\n",
        "num_decoder_tokens = len(target_char) + 1\n",
        "\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_text])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_text])\n",
        "print(num_encoder_tokens)\n",
        "print(num_decoder_tokens)\n",
        "print(max_encoder_seq_length)\n",
        "print(max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:46.319388Z",
          "iopub.status.busy": "2023-09-23T14:19:46.318555Z",
          "iopub.status.idle": "2023-09-23T14:19:46.325886Z",
          "shell.execute_reply": "2023-09-23T14:19:46.324927Z",
          "shell.execute_reply.started": "2023-09-23T14:19:46.319349Z"
        },
        "id": "EpIcpbOSkAc6",
        "outputId": "2af367c6-48ab-43b3-b93f-f59f5aa8aa64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 18416\n",
            "Number of unique input tokens: 9232\n",
            "Number of unique output tokens: 8666\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 42\n"
          ]
        }
      ],
      "source": [
        "# Printing the data\n",
        "print(\"Number of samples:\", len(input_text))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "UxZDzrqQkAc6"
      },
      "source": [
        "# 3. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JiW40SkKkAc6"
      },
      "source": [
        "# 3.1. Creating the Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:47.142287Z",
          "iopub.status.busy": "2023-09-23T14:19:47.141623Z",
          "iopub.status.idle": "2023-09-23T14:19:47.160049Z",
          "shell.execute_reply": "2023-09-23T14:19:47.158944Z",
          "shell.execute_reply.started": "2023-09-23T14:19:47.142254Z"
        },
        "id": "Ig-GG7EQkAc6"
      },
      "outputs": [],
      "source": [
        "# Creating the dictionary\n",
        "input_token_index = dict([(word,i+1)for i, word in enumerate(input_char)])\n",
        "target_token_index = dict([(word,i+1)for i, word in enumerate(target_char)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:48.235885Z",
          "iopub.status.busy": "2023-09-23T14:19:48.235531Z",
          "iopub.status.idle": "2023-09-23T14:19:48.245539Z",
          "shell.execute_reply": "2023-09-23T14:19:48.244482Z",
          "shell.execute_reply.started": "2023-09-23T14:19:48.235855Z"
        },
        "id": "zXNEbusVkAc6"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lIgLDOevkAc6"
      },
      "source": [
        "# 3.2. Creating the Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:49.654647Z",
          "iopub.status.busy": "2023-09-23T14:19:49.653930Z",
          "iopub.status.idle": "2023-09-23T14:19:50.015946Z",
          "shell.execute_reply": "2023-09-23T14:19:50.014858Z",
          "shell.execute_reply.started": "2023-09-23T14:19:49.654611Z"
        },
        "id": "jGmHvwI8kAc7"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X,y = df.english_sentence , df.hindi_sentence\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:51.554189Z",
          "iopub.status.busy": "2023-09-23T14:19:51.553656Z",
          "iopub.status.idle": "2023-09-23T14:19:51.559495Z",
          "shell.execute_reply": "2023-09-23T14:19:51.558496Z",
          "shell.execute_reply.started": "2023-09-23T14:19:51.554157Z"
        },
        "id": "NQlKh2SzkAc7",
        "outputId": "b7e96667-cdff-4af7-d023-119be92550c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16574,)\n",
            "(1842,)\n"
          ]
        }
      ],
      "source": [
        "# Printinng the shape\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:19:53.409778Z",
          "iopub.status.busy": "2023-09-23T14:19:53.409122Z",
          "iopub.status.idle": "2023-09-23T14:19:53.420637Z",
          "shell.execute_reply": "2023-09-23T14:19:53.419749Z",
          "shell.execute_reply.started": "2023-09-23T14:19:53.409743Z"
        },
        "id": "aKbzaI4HkAc7"
      },
      "outputs": [],
      "source": [
        "# Defining the batch\n",
        "def generate_batch(X,y,batch_size):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_encoder_seq_length),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_decoder_seq_length),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6RVbrcwtkAc7"
      },
      "source": [
        "# 3.3. Making the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:21:30.981008Z",
          "iopub.status.busy": "2023-09-23T14:21:30.980635Z",
          "iopub.status.idle": "2023-09-23T14:21:30.985780Z",
          "shell.execute_reply": "2023-09-23T14:21:30.984736Z",
          "shell.execute_reply.started": "2023-09-23T14:21:30.980958Z"
        },
        "id": "8bm39pA0kAc7"
      },
      "outputs": [],
      "source": [
        "latent_dim = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:21:36.184864Z",
          "iopub.status.busy": "2023-09-23T14:21:36.184492Z",
          "iopub.status.idle": "2023-09-23T14:21:41.759494Z",
          "shell.execute_reply": "2023-09-23T14:21:41.758452Z",
          "shell.execute_reply.started": "2023-09-23T14:21:36.184832Z"
        },
        "id": "pO17E95ykAc7"
      },
      "outputs": [],
      "source": [
        "# Making the Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
        "\n",
        "# Adding two more LSTM layers\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)\n",
        "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs3, state_h3, state_c3 = encoder_lstm3(encoder_outputs2)\n",
        "\n",
        "encoder_states = [state_h3, state_c3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8nA6kaMgkAc7"
      },
      "source": [
        "# 3.4. Making the Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:21:52.446781Z",
          "iopub.status.busy": "2023-09-23T14:21:52.446412Z",
          "iopub.status.idle": "2023-09-23T14:21:54.964469Z",
          "shell.execute_reply": "2023-09-23T14:21:54.963296Z",
          "shell.execute_reply.started": "2023-09-23T14:21:52.446750Z"
        },
        "id": "lTQNTvoBkAc7"
      },
      "outputs": [],
      "source": [
        "# Making the decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Adding two more LSTM layers\n",
        "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs1, _, _ = decoder_lstm1(dec_emb, initial_state=encoder_states)\n",
        "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs1)\n",
        "decoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs3, _, _ = decoder_lstm3(decoder_outputs2)\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pcFkg8dJkAc7"
      },
      "source": [
        "# 3.5. Making the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:23:00.888309Z",
          "iopub.status.busy": "2023-09-23T14:23:00.887740Z",
          "iopub.status.idle": "2023-09-23T14:23:00.928861Z",
          "shell.execute_reply": "2023-09-23T14:23:00.927983Z",
          "shell.execute_reply.started": "2023-09-23T14:23:00.888271Z"
        },
        "id": "Z2vTt4DVkAc7"
      },
      "outputs": [],
      "source": [
        "# Making the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc']) # For classification we use adam and for regression we use rmsprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:23:03.153326Z",
          "iopub.status.busy": "2023-09-23T14:23:03.152950Z",
          "iopub.status.idle": "2023-09-23T14:23:03.195745Z",
          "shell.execute_reply": "2023-09-23T14:23:03.195060Z",
          "shell.execute_reply.started": "2023-09-23T14:23:03.153299Z"
        },
        "id": "lOHQMdZwkAc8",
        "outputId": "5277afc0-7bf8-4e4a-c988-bc4c0c2ca3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 50)     461600      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 50),   20200       ['embedding[0][0]']              \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 50),   20200       ['lstm[0][0]']                   \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 50)     433300      ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 50),   20200       ['lstm_1[0][0]']                 \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 50),   20200       ['embedding_1[0][0]',            \n",
            "                                 (None, 50),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 50)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, None, 50),   20200       ['lstm_3[0][0]']                 \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, None, 50),   20200       ['lstm_4[0][0]']                 \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 8666)   441966      ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,458,066\n",
            "Trainable params: 1,458,066\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8oL-Oq50kAdC"
      },
      "source": [
        "# 4. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "W-GKVELRkAdC"
      },
      "source": [
        "# 4.1. Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:23:10.198664Z",
          "iopub.status.busy": "2023-09-23T14:23:10.198311Z",
          "iopub.status.idle": "2023-09-23T14:23:10.205243Z",
          "shell.execute_reply": "2023-09-23T14:23:10.202437Z",
          "shell.execute_reply.started": "2023-09-23T14:23:10.198636Z"
        },
        "id": "4Htys1nvkAdC"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 512\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "P1DDgCIEkAdC"
      },
      "source": [
        "# 4.2. Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T14:23:14.542773Z",
          "iopub.status.busy": "2023-09-23T14:23:14.542064Z",
          "iopub.status.idle": "2023-09-23T15:56:22.723442Z",
          "shell.execute_reply": "2023-09-23T15:56:22.722359Z",
          "shell.execute_reply.started": "2023-09-23T14:23:14.542728Z"
        },
        "id": "bP35bOGLkAdC",
        "outputId": "f18bdc43-63d9-4142-bf48-938810f0d8af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28/1164885454.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 100s 2s/step - loss: 9.0152 - acc: 0.0424 - val_loss: 8.7644 - val_acc: 0.0434\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 7.8140 - acc: 0.0449 - val_loss: 7.2922 - val_acc: 0.0434\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 7.0481 - acc: 0.0449 - val_loss: 7.2119 - val_acc: 0.0434\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 54s 2s/step - loss: 6.9833 - acc: 0.0449 - val_loss: 7.2363 - val_acc: 0.0434\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.9641 - acc: 0.0449 - val_loss: 7.2586 - val_acc: 0.0434\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.9525 - acc: 0.0447 - val_loss: 7.2800 - val_acc: 0.0434\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.9420 - acc: 0.0447 - val_loss: 7.2986 - val_acc: 0.0434\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.9329 - acc: 0.0448 - val_loss: 7.3048 - val_acc: 0.0434\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 57s 2s/step - loss: 6.9278 - acc: 0.0447 - val_loss: 7.3036 - val_acc: 0.0434\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.9180 - acc: 0.0450 - val_loss: 7.3042 - val_acc: 0.0434\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.9071 - acc: 0.0447 - val_loss: 7.3094 - val_acc: 0.0434\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.9037 - acc: 0.0447 - val_loss: 7.3141 - val_acc: 0.0434\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8988 - acc: 0.0450 - val_loss: 7.3211 - val_acc: 0.0434\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8910 - acc: 0.0451 - val_loss: 7.3294 - val_acc: 0.0434\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.8855 - acc: 0.0451 - val_loss: 7.3380 - val_acc: 0.0434\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8806 - acc: 0.0451 - val_loss: 7.3455 - val_acc: 0.0434\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8726 - acc: 0.0451 - val_loss: 7.3511 - val_acc: 0.0434\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8695 - acc: 0.0450 - val_loss: 7.3594 - val_acc: 0.0434\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8651 - acc: 0.0453 - val_loss: 7.3666 - val_acc: 0.0440\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8551 - acc: 0.0450 - val_loss: 7.3622 - val_acc: 0.0437\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.8425 - acc: 0.0450 - val_loss: 7.3415 - val_acc: 0.0462\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.8197 - acc: 0.0537 - val_loss: 7.3188 - val_acc: 0.0542\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.7958 - acc: 0.0544 - val_loss: 7.3050 - val_acc: 0.0545\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.7755 - acc: 0.0546 - val_loss: 7.2922 - val_acc: 0.0567\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.7570 - acc: 0.0556 - val_loss: 7.2811 - val_acc: 0.0573\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.7376 - acc: 0.0561 - val_loss: 7.2786 - val_acc: 0.0573\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.7193 - acc: 0.0561 - val_loss: 7.2768 - val_acc: 0.0573\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.7034 - acc: 0.0561 - val_loss: 7.2758 - val_acc: 0.0573\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.6886 - acc: 0.0560 - val_loss: 7.2691 - val_acc: 0.0570\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.6685 - acc: 0.0564 - val_loss: 7.2625 - val_acc: 0.0567\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.6372 - acc: 0.0583 - val_loss: 7.2527 - val_acc: 0.0584\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.6087 - acc: 0.0607 - val_loss: 7.2395 - val_acc: 0.0630\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 54s 2s/step - loss: 6.5778 - acc: 0.0630 - val_loss: 7.2465 - val_acc: 0.0587\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.5571 - acc: 0.0655 - val_loss: 7.2297 - val_acc: 0.0604\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 54s 2s/step - loss: 6.5195 - acc: 0.0678 - val_loss: 7.2174 - val_acc: 0.0641\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.4849 - acc: 0.0717 - val_loss: 7.2116 - val_acc: 0.0644\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.4450 - acc: 0.0722 - val_loss: 7.2001 - val_acc: 0.0627\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.4165 - acc: 0.0739 - val_loss: 7.1778 - val_acc: 0.0666\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.3837 - acc: 0.0744 - val_loss: 7.1777 - val_acc: 0.0675\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.3466 - acc: 0.0751 - val_loss: 7.1509 - val_acc: 0.0681\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.3144 - acc: 0.0756 - val_loss: 7.1397 - val_acc: 0.0678\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.2998 - acc: 0.0761 - val_loss: 7.1388 - val_acc: 0.0678\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.2789 - acc: 0.0766 - val_loss: 7.1089 - val_acc: 0.0658\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.2399 - acc: 0.0763 - val_loss: 7.0831 - val_acc: 0.0689\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.2096 - acc: 0.0767 - val_loss: 7.0674 - val_acc: 0.0686\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.1799 - acc: 0.0774 - val_loss: 7.0584 - val_acc: 0.0683\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.1468 - acc: 0.0789 - val_loss: 7.0381 - val_acc: 0.0701\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 6.1194 - acc: 0.0838 - val_loss: 7.0101 - val_acc: 0.0743\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.0820 - acc: 0.0878 - val_loss: 6.9929 - val_acc: 0.0769\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.0400 - acc: 0.0907 - val_loss: 6.9971 - val_acc: 0.0811\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 6.0180 - acc: 0.0933 - val_loss: 6.9581 - val_acc: 0.0831\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.9953 - acc: 0.0954 - val_loss: 6.9627 - val_acc: 0.0786\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.9706 - acc: 0.0965 - val_loss: 6.9253 - val_acc: 0.0834\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.9502 - acc: 0.0988 - val_loss: 6.9419 - val_acc: 0.0822\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.9125 - acc: 0.1011 - val_loss: 6.8935 - val_acc: 0.0876\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.8788 - acc: 0.1044 - val_loss: 6.8923 - val_acc: 0.0851\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.8490 - acc: 0.1057 - val_loss: 6.8803 - val_acc: 0.0874\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.8191 - acc: 0.1068 - val_loss: 6.8741 - val_acc: 0.0862\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.7930 - acc: 0.1087 - val_loss: 6.8543 - val_acc: 0.0876\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.7599 - acc: 0.1094 - val_loss: 6.8458 - val_acc: 0.0893\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.7399 - acc: 0.1104 - val_loss: 6.8369 - val_acc: 0.0888\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.7190 - acc: 0.1103 - val_loss: 6.8532 - val_acc: 0.0868\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.6916 - acc: 0.1109 - val_loss: 6.8175 - val_acc: 0.0916\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 57s 2s/step - loss: 5.6550 - acc: 0.1131 - val_loss: 6.8081 - val_acc: 0.0919\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.6200 - acc: 0.1143 - val_loss: 6.8145 - val_acc: 0.0905\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.5773 - acc: 0.1174 - val_loss: 6.7716 - val_acc: 0.0933\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 54s 2s/step - loss: 5.5509 - acc: 0.1198 - val_loss: 6.7669 - val_acc: 0.0927\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.5091 - acc: 0.1221 - val_loss: 6.7721 - val_acc: 0.0916\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.4724 - acc: 0.1252 - val_loss: 6.7871 - val_acc: 0.0910\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.4468 - acc: 0.1265 - val_loss: 6.7489 - val_acc: 0.0947\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.4231 - acc: 0.1291 - val_loss: 6.7438 - val_acc: 0.0995\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.4027 - acc: 0.1313 - val_loss: 6.7719 - val_acc: 0.0987\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.3693 - acc: 0.1326 - val_loss: 6.7333 - val_acc: 0.1024\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.3285 - acc: 0.1371 - val_loss: 6.7402 - val_acc: 0.1010\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.2992 - acc: 0.1380 - val_loss: 6.7428 - val_acc: 0.1061\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.2662 - acc: 0.1410 - val_loss: 6.7483 - val_acc: 0.1052\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.2352 - acc: 0.1451 - val_loss: 6.7415 - val_acc: 0.1044\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.2080 - acc: 0.1459 - val_loss: 6.7210 - val_acc: 0.1044\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.1923 - acc: 0.1485 - val_loss: 6.7274 - val_acc: 0.1061\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.1753 - acc: 0.1486 - val_loss: 6.7242 - val_acc: 0.1064\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.1422 - acc: 0.1508 - val_loss: 6.6946 - val_acc: 0.1092\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.1078 - acc: 0.1548 - val_loss: 6.7009 - val_acc: 0.1064\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.0833 - acc: 0.1564 - val_loss: 6.7186 - val_acc: 0.1081\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.0670 - acc: 0.1564 - val_loss: 6.7435 - val_acc: 0.1078\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 54s 2s/step - loss: 5.0457 - acc: 0.1579 - val_loss: 6.7563 - val_acc: 0.1069\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 5.0270 - acc: 0.1585 - val_loss: 6.7261 - val_acc: 0.1081\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 5.0133 - acc: 0.1604 - val_loss: 6.7425 - val_acc: 0.1072\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.9836 - acc: 0.1603 - val_loss: 6.7886 - val_acc: 0.1072\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.9647 - acc: 0.1626 - val_loss: 6.7694 - val_acc: 0.1095\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.9527 - acc: 0.1636 - val_loss: 6.7138 - val_acc: 0.1123\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.9276 - acc: 0.1663 - val_loss: 6.7197 - val_acc: 0.1140\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.8895 - acc: 0.1691 - val_loss: 6.7739 - val_acc: 0.1157\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 4.8598 - acc: 0.1713 - val_loss: 6.7551 - val_acc: 0.1134\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 4.8466 - acc: 0.1726 - val_loss: 6.7238 - val_acc: 0.1140\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.8257 - acc: 0.1743 - val_loss: 6.7564 - val_acc: 0.1140\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 4.7945 - acc: 0.1764 - val_loss: 6.7820 - val_acc: 0.1134\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 4.7722 - acc: 0.1784 - val_loss: 6.7437 - val_acc: 0.1143\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 56s 2s/step - loss: 4.7556 - acc: 0.1794 - val_loss: 6.7698 - val_acc: 0.1134\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.7306 - acc: 0.1820 - val_loss: 6.7746 - val_acc: 0.1177\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 55s 2s/step - loss: 4.7165 - acc: 0.1840 - val_loss: 6.7439 - val_acc: 0.1149\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e619c33b9d0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fitting the model\n",
        "\n",
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6tuS6RaikAdC"
      },
      "source": [
        "# 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "k0LSWKuAkAdC"
      },
      "source": [
        "# 5.1. Printing the Validation Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:08:47.401524Z",
          "iopub.status.busy": "2023-09-23T16:08:47.401156Z",
          "iopub.status.idle": "2023-09-23T16:08:53.780162Z",
          "shell.execute_reply": "2023-09-23T16:08:53.779049Z",
          "shell.execute_reply.started": "2023-09-23T16:08:47.401495Z"
        },
        "id": "BpOpW-kGkAdC",
        "outputId": "81f0e03e-6486-4ad6-90e5-03bfc8e03728"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28/2723858562.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  model.evaluate_generator(generator = generate_batch(X_test, y_test, batch_size = batch_size), steps = val_samples//batch_size)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[6.74385404586792, 0.11486103385686874]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Printing the validation score\n",
        "model.evaluate_generator(generator = generate_batch(X_test, y_test, batch_size = batch_size), steps = val_samples//batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xSbV9HGAkAdD"
      },
      "source": [
        "# 5.2. Saving the Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:08:53.782922Z",
          "iopub.status.busy": "2023-09-23T16:08:53.782332Z",
          "iopub.status.idle": "2023-09-23T16:08:53.825315Z",
          "shell.execute_reply": "2023-09-23T16:08:53.824397Z",
          "shell.execute_reply.started": "2023-09-23T16:08:53.782886Z"
        },
        "id": "bQtubBbzkAdD"
      },
      "outputs": [],
      "source": [
        "# Saving the weights\n",
        "model.save_weights('nmt_eng_hin_translation.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "QG12OlH6kAdD"
      },
      "source": [
        "# 6. Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mdaFAMA1kAdD"
      },
      "source": [
        "# 6.1. Making the Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:08:53.827392Z",
          "iopub.status.busy": "2023-09-23T16:08:53.826506Z",
          "iopub.status.idle": "2023-09-23T16:08:53.836640Z",
          "shell.execute_reply": "2023-09-23T16:08:53.835587Z",
          "shell.execute_reply.started": "2023-09-23T16:08:53.827360Z"
        },
        "id": "ZLT_-MQSkAdD"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "\n",
        "encoder_model = Model(encoder_inputs,encoder_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "W2i62p_ikAdD"
      },
      "source": [
        "# 6.2. Making the Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:08:53.839917Z",
          "iopub.status.busy": "2023-09-23T16:08:53.839584Z",
          "iopub.status.idle": "2023-09-23T16:08:53.846903Z",
          "shell.execute_reply": "2023-09-23T16:08:53.845881Z",
          "shell.execute_reply.started": "2023-09-23T16:08:53.839886Z"
        },
        "id": "yNvSXAT6kAdD"
      },
      "outputs": [],
      "source": [
        "# Decoder Setup\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:15:42.230635Z",
          "iopub.status.busy": "2023-09-23T16:15:42.230071Z",
          "iopub.status.idle": "2023-09-23T16:15:43.068545Z",
          "shell.execute_reply": "2023-09-23T16:15:43.067554Z",
          "shell.execute_reply.started": "2023-09-23T16:15:42.230603Z"
        },
        "id": "VGXOoPqdkAdD"
      },
      "outputs": [],
      "source": [
        "dec_emb2 = dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm3(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:15:46.568369Z",
          "iopub.status.busy": "2023-09-23T16:15:46.568005Z",
          "iopub.status.idle": "2023-09-23T16:15:46.577649Z",
          "shell.execute_reply": "2023-09-23T16:15:46.576690Z",
          "shell.execute_reply.started": "2023-09-23T16:15:46.568341Z"
        },
        "id": "7Pu6429XkAdD"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    #target_seq[0, 0] = target_token_index['START_']\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == ' _END' or len(decoded_sentence) > 25):\n",
        "            stop_condition = True\n",
        "            # Update the target sequence (of length 1).\n",
        "            target_seq = np.zeros((1,1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            # Update states\n",
        "            states_value = [h, c]\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "FYJHVbuwkAdD"
      },
      "source": [
        "# 6.3. Printing the Predicted Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:15:47.361176Z",
          "iopub.status.busy": "2023-09-23T16:15:47.360800Z",
          "iopub.status.idle": "2023-09-23T16:15:47.366149Z",
          "shell.execute_reply": "2023-09-23T16:15:47.365097Z",
          "shell.execute_reply.started": "2023-09-23T16:15:47.361145Z"
        },
        "id": "R0-GH0G7kAdE"
      },
      "outputs": [],
      "source": [
        "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T16:15:48.389109Z",
          "iopub.status.busy": "2023-09-23T16:15:48.388723Z",
          "iopub.status.idle": "2023-09-23T16:15:53.777072Z",
          "shell.execute_reply": "2023-09-23T16:15:53.776049Z",
          "shell.execute_reply.started": "2023-09-23T16:15:48.389076Z"
        },
        "id": "wMOC9j5ykAdE",
        "outputId": "fd4579d9-0b1b-452d-eaf3-a28b7de1ebef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input English sentence: class west bengal\n",
            "Actual Hindi Translation: श्रेणीपश्चिम बंगाल\n",
            "Predicted Hindi Translation:  झंडा झंडा झंडा झंडा झंडा झंडा\n"
          ]
        }
      ],
      "source": [
        "k+=2\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_test[k:k+1].values[0])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0NoSnZdkAdE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "004f67742dab10302625fae45e5600b05f1188db265e9fd73c0f303fae8bc9c7"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}